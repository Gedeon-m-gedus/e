{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a64697a-700f-453e-9608-08c8ddf30ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "https://www.youtube.com/watch?v=qQpajSD2neA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71fc4580-39a3-4214-8170-83a270b42837",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d56e12-2e1c-41eb-8ea5-621155c281dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.utils.prune as prune\n",
    "import timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "151b58c5-fccd-4d36-9e23-e27561840439",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "491fced1-7477-46ef-9911-038e0bb5198b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11aa10ce-8ef5-4e70-b6a4-ec3d2673b45b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff69bd8-a746-46aa-9884-018db16e31ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python inference.py \\\n",
    "    --onnx_model_path  nano/xcit_nano_12_p16_224.fb_dist_in1k/averaged/best_model.onnx \\\n",
    "    --img_path ../../../datasets/hymenoptera_data/val/bees/ \\\n",
    "    --dataset_dir_or_classes_file ../../../datasets/hymenoptera_data/ \\\n",
    "    --output_dir nano_avg_inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c1678d-814d-47a4-b862-764a2a2b6929",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "697becaa-bfc0-46d2-9b28-797de39bacc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from explainability import explain_model\n",
    "\n",
    "class Args:\n",
    "    def __init__(self):\n",
    "        self.output_dir = \"nnnano/xcit_nano_12_p8_224.fb_dist_in1k\"\n",
    "        self.dataset_dir = \"../../../datasets/hymenoptera_data\"\n",
    "        self.model_name = \"xcit_nano_12_p8_224.fb_dist_in1k\"\n",
    "        self.crop_size = 224\n",
    "        self.batch_size = 30\n",
    "        self.num_workers = 16\n",
    "        self.n_samples = 4\n",
    "        self.max_evals = 700\n",
    "        self.topk = 4\n",
    "        self.dropout = 0.2\n",
    "        self.gray = False\n",
    "        self.feat_extract = True\n",
    "    \n",
    "args = Args()\n",
    "\n",
    "explain_model(\n",
    "    args = args\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a6392bc-c29c-4a37-bacd-4cfb10f03e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from explainability import explain_model\n",
    "\n",
    "class Args:\n",
    "    def __init__(self):\n",
    "        self.output_dir = \"nnnano/xcit_nano_12_p16_224.fb_dist_in1k/averaged\"\n",
    "        self.dataset_dir = \"../../../datasets/hymenoptera_data\"\n",
    "        self.model_name = \"xcit_nano_12_p16_224.fb_dist_in1k\"\n",
    "        self.crop_size = 224\n",
    "        self.batch_size = 30\n",
    "        self.num_workers = 16\n",
    "        self.n_samples = 4\n",
    "        self.max_evals = 700\n",
    "        self.topk = 4\n",
    "        self.dropout = 0.2\n",
    "    \n",
    "args = Args()\n",
    "\n",
    "explain_model(\n",
    "    args = args\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c98e234-8474-4002-8691-5cb3f45cde94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ffbde43-00cc-43de-90b7-405b7f3d8b1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a02f7b03-6259-4238-a8bb-cb773847607e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a41d10-5a11-482d-9b12-c3ddb0ce6156",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff5f6a3-1e64-470a-9814-498e99e1f862",
   "metadata": {},
   "outputs": [],
   "source": [
    "python tune.py \\\n",
    "    --name  \\\n",
    "    --output_dir <model_checkpoint_dir> \\\n",
    "    --dataset_dir <dataset_dir> \\\n",
    "    --model_name swinv2_cr_tiny_ns_224 \\\n",
    "    --tune_batch_size \\\n",
    "    --tune_opt \\\n",
    "    --pbt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f427d32-1222-497f-a2d8-3c9e92bcaa26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4758cc-6b1c-410e-81e8-fb592f90279d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3246162e-ed55-4161-abd7-6aa5b7513575",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d24f4a5-9d0e-4910-93fe-c417f5008338",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isdir(\"../../../datasets/weather_data/test/\"):\n",
    "    print(\"Yes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd700f84-dead-40e5-b181-eacfa81e9ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2652a21c-ffd8-4fae-88ae-09a9b7a46734",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir, model_name = \"nano\", \"xcit_nano_12_p16_224.fb_dist_in1k\"\n",
    "checkpoint_file = os.path.join(output_dir, model_name, \"best_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd25223-ee9a-45eb-a177-88f41ee4be33",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir, model_name = \"nano\", \"xcit_nano_12_p16_224.fb_dist_in1k\"\n",
    "checkpoint_file = os.path.join(output_dir, model_name, \"averaged\", \"best_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c34bcc18-b395-4ec2-ab5c-dc6210b3898a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef5abd79-0038-4057-86b5-c6e6474ab23b",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.path.basename(\"../../../datasets/hymenoptera_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "488252a5-5596-4183-921e-ef263b4cd54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.utils.prune as prune\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Define the base model architecture\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(784, 300)\n",
    "        self.fc2 = nn.Linear(300, 100)\n",
    "        self.fc3 = nn.Linear(100, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = nn.functional.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = nn.functional.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# Train the base model\n",
    "def train(model, train_loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "# Evaluate the model\n",
    "def test(model, test_loader, criterion, device):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += criterion(output, target).item()\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    accuracy = 100. * correct / len(test_loader.dataset)\n",
    "    return test_loss, accuracy\n",
    "\n",
    "def main():\n",
    "    # Set random seed for reproducibility\n",
    "    torch.manual_seed(1234)\n",
    "\n",
    "    # Set device\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # Load the MNIST dataset\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        datasets.MNIST('./data', train=True, download=True, transform=transforms.ToTensor()),\n",
    "        batch_size=64, shuffle=True)\n",
    "\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        datasets.MNIST('./data', train=False, transform=transforms.ToTensor()),\n",
    "        batch_size=1000, shuffle=False)\n",
    "\n",
    "    # Create the base model\n",
    "    model = Net().to(device)\n",
    "\n",
    "    # Define the loss function and optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    # Train the base model\n",
    "    for epoch in range(3):\n",
    "        train(model, train_loader, criterion, optimizer, device)\n",
    "        test_loss, accuracy = test(model, test_loader, criterion, device)\n",
    "        print(f\"Epoch {epoch+1}: Test Loss = {test_loss:.4f}, Accuracy = {accuracy:.2f}%\")\n",
    "\n",
    "    # Prune the model\n",
    "    parameters_to_prune = (\n",
    "        (model.fc1, \"weight\"),\n",
    "        (model.fc2, \"weight\"),\n",
    "        (model.fc3, \"weight\")\n",
    "    )\n",
    "    prune.global_unstructured(\n",
    "        parameters_to_prune,\n",
    "        pruning_method=prune.L1Unstructured,\n",
    "        amount=0.2\n",
    "    )\n",
    "\n",
    "    # Retrain the pruned model\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    for epoch in range(3):\n",
    "        train(model, train_loader, criterion, optimizer, device)\n",
    "        test_loss, accuracy = test(model, test_loader, criterion, device)\n",
    "        print(f\"Epoch {epoch+1}: Test Loss = {test_loss:.4f}, Accuracy = {accuracy:.2f}%\")\n",
    "\n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c832447-6615-4108-801d-daefe4680549",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de9706a6-417e-42bc-a9dd-34e903f0104a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fbf4fa3-adc8-4cb2-8ec6-7f88cebb7243",
   "metadata": {},
   "outputs": [],
   "source": [
    "import timm\n",
    "import torch.nn.utils.prune as prune\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b458e3-3eae-4078-b329-7aa510357960",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = timm.create_model('resnet18', pretrained=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf19669a-65ec-421b-ab22-94f7fae06ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = timm.list_models(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9326ff1e-50d1-40a9-ab45-00435d14b68f",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(model_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c953081a-8ed5-4272-a122-305c8b0134fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_to_prune = [(module, 'weight') for module in model.modules() if isinstance(module, (nn.Conv2d, nn.Linear))]\n",
    "prune.global_unstructured(\n",
    "    parameters_to_prune,\n",
    "    pruning_method=prune.LnStructured()L1Unstructured,\n",
    "    amount=0.3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95467d2e-96ba-41e6-bc8a-292aca983f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check sparsity of pruned parameters\n",
    "total_params = 0\n",
    "pruned_params = 0\n",
    "for module, _ in parameters_to_prune:\n",
    "    mask = prune.remove(module, 'weight')\n",
    "    pruned_params += torch.sum(module.weight == 0).item()\n",
    "    total_params += module.weight.nelement()\n",
    "\n",
    "sparsity = pruned_params / total_params\n",
    "print(f\"Model: {model.__class__}, Sparsity: {sparsity:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e4dfcd-a012-40a1-90be-9717aecc22df",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f37f8e1-ede9-4c4d-97a8-8b639f5d535f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pruned_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb9c3dc8-5fb2-4019-bc0f-a78363651d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.utils.prune as prune\n",
    "import torch\n",
    "import timm\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32766af6-16ef-4ba5-8a6b-f8e651a85581",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = utils.get_model(model_name=\"xcit_nano_12_p8_224.fb_dist_in1k\",\n",
    "                        num_classes=2, \n",
    "                        dropout=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d10a3f-fae1-457c-b51c-e5b2baefc70c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.utils.prune as prune\n",
    "from typing import List, Tuple\n",
    "\n",
    "def prune_model(model: nn.Module, pruning_rate: float) -> List[Tuple[nn.Module, str]]:\n",
    "    \"\"\"\n",
    "    Applies structured pruning to the specified modules of the model.\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module): The model to be pruned.\n",
    "        pruning_rate (float): The fraction of weights to be pruned.\n",
    "\n",
    "    Returns:\n",
    "        List[Tuple[nn.Module, str]]: A list of tuples containing the pruned modules and parameter names.\n",
    "    \"\"\"\n",
    "    parameters_to_prune = [(module, 'weight') for module in model.modules() if\n",
    "                           isinstance(module, torch.nn.Conv2d) or\n",
    "                           isinstance(module, torch.nn.Linear)\n",
    "                           ]\n",
    " \n",
    "    prune.global_unstructured(\n",
    "        parameters_to_prune, \n",
    "        pruning_method=prune.L1Unstructured, \n",
    "        amount=pruning_rate\n",
    "    )\n",
    "   \n",
    "    return parameters_to_prune\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d508ff3f-9c02-460a-83a9-a5d9dd3b5d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "prune_model(model, pruning_rate = 2, pruning_method = 'l2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d52e72d-4774-48ae-b35b-c41c9d03fc42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af8b57c-d68b-44b0-8d16-f7fa573cd3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "prune.global_unstructured(\n",
    "    parameters_to_prune,\n",
    "    pruning_method=prune.LnStructured(amount=0.2, n=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ebc1979-ae04-43e9-bb2c-e62fce03f320",
   "metadata": {},
   "outputs": [],
   "source": [
    "for module, parameter_name in parameters_to_prune:\n",
    "    prune.remove(module, parameter_name)\n",
    "    # print(parameter_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "623631bf-1b50-4e64-83f4-14fc647b1184",
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt = torch.load(\n",
    "    \"nano/xcit_nano_12_p8_224.fb_dist_in1k/best_model_0.9467.pth\", \n",
    "    map_location=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78dad183-3aba-4745-9a5e-6349c33d5ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "prune."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "623b8d3a-9c72-4535-b334-a5a2dac9c182",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1836e164-7420-4e4d-8991-49684ebac740",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e17601-bc16-48df-a65f-2fe775a851e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c05eca16-dce8-4a4d-bb10-5db421512c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "prune.remove(ckpt[\"model\"], 'weight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a5cfd3-db7b-43eb-997b-ba4c80b4f62a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f2ce8c-4679-4db7-80de-7322ada0f693",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b7de33e-3488-4b40-9a1c-63e769d3bb71",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from utils import create_train_val_test_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f4c7638-eda8-49d3-8afa-7c9ea705f241",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_train_val_test_splits(\"../../../datasets/flower_photos/\", \"../../../datasets/flower_data/\", ratio=(0.8, 0.1, 0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37323374-e8f0-45fb-b196-48dde64e645a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d27eea-52c7-4aad-b032-305551f5931c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69db1e45-0029-4879-97d8-59a6f5153cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import timm\n",
    "from torch import optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbcc82b4-390c-4d1b-b391-2d140923af7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from timm.optim import create_optimizer_v2, optimizer_kwargs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99431334-1393-4221-945b-8a8a592c6c69",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = timm.create_model(\"resnet18\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113292c3-0752-4d16-9fa0-71d6d8995c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "op = create_optimizer_v2(model.fc.parameters(), opt=\"adahessian\", lr=0.002, weight_decay=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18df8042-37a3-4a64-b001-d84e617686f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "optim.lr_scheduler.CosineAnnealingLR(op, T_max=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f2ff0a-ac0b-4371-9c5c-dbbf6f84dfcd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Define the CNN model\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.fc = nn.Linear(32 * 8 * 8, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "def fgsm_attack(model, input_data, true_labels, epsilon):\n",
    "    model.eval()\n",
    "    input_data.requires_grad = True\n",
    "\n",
    "    # Forward pass\n",
    "    output = model(input_data)\n",
    "\n",
    "    # Calculate the loss\n",
    "    loss = nn.functional.cross_entropy(output, true_labels)\n",
    "\n",
    "    # Backward pass to obtain the gradients\n",
    "    model.zero_grad()\n",
    "    loss.backward()\n",
    "\n",
    "    # Normalize the gradients by taking the sign\n",
    "    gradients = input_data.grad.data\n",
    "    normalized_gradients = torch.sign(gradients)\n",
    "\n",
    "    # Generate the perturbation\n",
    "    perturbation = epsilon * normalized_gradients\n",
    "\n",
    "    # Create the adversarial example by adding the perturbation to the input data\n",
    "    adversarial_example = input_data + perturbation\n",
    "\n",
    "    # Clip the adversarial example to ensure it stays within a valid range\n",
    "    adversarial_example = torch.clamp(adversarial_example, 0, 1)\n",
    "\n",
    "    return adversarial_example\n",
    "\n",
    "def train(model, train_loader, epsilon, optimizer, criterion, num_epochs):\n",
    "    model.train()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        for inputs, labels in train_loader:\n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Generate adversarial examples using FGSM\n",
    "            adversarial_inputs = fgsm_attack(model, inputs, labels, epsilon)\n",
    "\n",
    "            # Forward pass with adversarial examples\n",
    "            adversarial_outputs = model(adversarial_inputs)\n",
    "            adversarial_loss = criterion(adversarial_outputs, labels)\n",
    "\n",
    "            # Total loss for adversarial training\n",
    "            total_loss = loss + adversarial_loss\n",
    "\n",
    "            # Backward pass and optimization\n",
    "            optimizer.zero_grad()\n",
    "            total_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # Print training progress\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {total_loss.item()}\")\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Set hyperparameters\n",
    "epsilon = 0.05\n",
    "learning_rate = 0.001\n",
    "num_epochs = 10\n",
    "batch_size = 64\n",
    "\n",
    "# Data loading and preprocessing\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Initialize the CNN model\n",
    "model = CNN().to(device)\n",
    "\n",
    "# Define loss criterion and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Start training with FGSM adversarial training\n",
    "train(model, train_loader, epsilon, optimizer, criterion, num_epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c7a7b3-57f9-4143-892a-39f7d99d32f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f7dcccf-a75a-4cb5-8167-f076b42e10c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f64a5a-7b31-4a86-98ba-696a9672edab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import timm\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4469ca0c-ef1a-4fbc-bdce-4a086a0f6689",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_name = \"xcit_nano_12_p8_224.fb_in1k\"\n",
    "feat_extract = True\n",
    "dropout = 0.3\n",
    "num_classes = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d42be444-116f-4cea-92e4-f18512aaf54f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = timm.create_model(\n",
    "        model_name,\n",
    "        pretrained=True,\n",
    "        scriptable=True,\n",
    "        exportable=True,\n",
    "        drop_rate=dropout,\n",
    "        in_chans=1\n",
    "    )\n",
    "\n",
    "if feat_extract:\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "if isinstance(model.head, nn.Linear):\n",
    "    model.head = nn.Linear(model.head.in_features, num_classes, bias=True)\n",
    "elif hasattr(model.head, \"fc\") and isinstance(model.head.fc, nn.Linear):\n",
    "    model.head.fc = nn.Linear(model.head.fc.in_features, num_classes, bias=True)\n",
    "\n",
    "if hasattr(model, \"head_dist\") and isinstance(model.head_dist, nn.Linear):\n",
    "    model.head_dist = nn.Linear(model.head_dist.in_features, num_classes, bias=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40257b39-5b27-4b9a-b831-06da941de2dd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "list(filter(lambda param: param.requires_grad, model.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9218002-456f-4d81-a8b0-025776325d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "0  xcit_nano_12_p8_224.fb_in1k  0.92  0.9904  0.9181     0.9187    0.92\n",
    "0  xcit_nano_12_p8_224.fb_in1k  0.9317  0.9912  0.9342     0.9438  0.9317"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e580c068-029c-449a-82a0-02844196ff0e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model1 = timm.create_model(\n",
    "        model_name,\n",
    "        pretrained=True,\n",
    "        scriptable=True,\n",
    "        exportable=True,\n",
    "        drop_rate=dropout,\n",
    "        in_chans=1,\n",
    "        num_classes=num_classes\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb07536-b953-4a54-8ec7-d3cdd15a8f59",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for param in model1.parameters():\n",
    "    param.requires_grad = False\n",
    "for param in model1.get_classifier().parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe1e7a72-24cc-45f8-8df7-ba8e23b62a93",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73cbff1c-05d2-43f6-a850-f024fe3675a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "rm -rf __pycache__/ mlruns/ sample_runs/ && python train.py --dataset_dir ../../../datasets/weather_data/ --output_dir sample_runs --experiment_name nano --model_name xcit_nano_12_p8_224.fb_in1k --crop_size 224 --batch_size 16 --epochs 10 --prune --feat_extract --sched_name cosine_wr --opt_name madgrad --aug_type augmix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de82509-d340-40f0-a915-802fe736c5ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "988bef07-bfa3-4634-b05b-9ec85b89fc6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83dbb27f-5a49-4004-9f2c-0e967c018ecf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import timm\n",
    "import torch\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0031230a-33c0-4f9b-aee5-028ee30c0202",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a607fb19-1273-49d1-875a-c2c0e492b6ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "image_size, model_size = 224, \"nano\"\n",
    "\n",
    "matching_models = utils.get_matching_model_names(image_size, model_size)\n",
    "matching_models = [\n",
    "        name for name in matching_models if isinstance(list(timm.create_model(name).named_modules())[-1][1],\n",
    "                                                       torch.nn.Linear)\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa6da54-f6ac-4cbc-b043-a8f922abc169",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "matching_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b91db4a-bf8f-4471-b432-ed5e20315a2a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sorted(matching_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce08a618-5518-48f5-8bf4-395b43ad0c23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf0a4da2-279b-4216-9864-6ed5e40dde65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e03d3cb-0773-428b-bf08-d6cdf137e6ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ffa81fc-5584-4ddd-b77d-82481f8522ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_name = \"eva02_tiny_patch14_224.mim_in22k\"\n",
    "model = timm.create_model(\n",
    "        model_name,\n",
    "        pretrained=True,\n",
    "        scriptable=True,\n",
    "        exportable=True,\n",
    "        drop_rate=0.3,\n",
    "        in_chans=1\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b4d13bb-e20c-4b79-966d-61ffc21eaea4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a6d0fe-1441-4d1b-a634-017ba8ee3bb3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779f1706-3381-4032-938e-747186a961ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74aae4bd-03b1-42b2-bc0e-de6f379da275",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import torchvision.transforms as T\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f5c436-587e-4e1f-828f-9c3fdc1a2e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = utils.load_image_dataset(\"../../../datasets/weather_data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aca87cd-5b96-4540-bde5-1f2dc05fd441",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a8dd86-ddd2-49f4-adf7-faa7aeb0d903",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize(examples):\n",
    "    examples[\"pixel_values\"] = [image.convert(\"RGB\").resize((100,100)) for image in examples[\"image\"]]\n",
    "    return examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "790aca72-abc6-462b-aa0b-8c88536cb39e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds = ds.map(resize, remove_columns=[\"image\"], batched=True)\n",
    "# ds[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c514df87-0e61-496c-92c0-954fdff48255",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds.column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "570c5eec-4c87-4ca0-80b8-ef4e6fde64e6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torchvision.transforms import Compose, ColorJitter, ToTensor, RandomResizedCrop\n",
    "jitter = Compose(\n",
    "    [RandomResizedCrop(224),\n",
    "     ColorJitter(brightness=0.25, contrast=0.25, saturation=0.25, hue=0.5),\n",
    "     ToTensor(),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8351527-e877-488a-a065-ce058b637c8f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def augment(examples):\n",
    "    examples[\"pixel_values\"] = [jitter(image.convert(\"RGB\")) for image in examples[\"pixel_values\"]]\n",
    "    return examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5534c727-fc61-4306-99f4-bad2e16e345e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds[\"train\"].set_transform(augment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e78f2499-27a7-4230-9b3b-ff4a537643e2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56bed4bb-fcaa-4140-8421-8a72aac8d46d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "train_loader = DataLoader(ds[\"train\"], batch_size=8, shuffle=True, pin_memory=True, num_workers=4, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93694986-d2a1-4c2f-be21-2decf27da5a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for batch in train_loader:\n",
    "    print(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b59db1b1-3122-49d8-9ce4-73c53704c6ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3967e7bf-c1cc-4265-8c9b-08cf9c42ddfc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f572a5e0-c436-4c53-9f17-6c7acdec7fd5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c64b7499-fef8-4a61-aa50-85b1c4068d13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1625f8ad-6302-4e6b-b1c1-80dec7ddc98f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "715c4252-b73e-49c8-8f8f-43f137f4f11b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c5fd75b-0d20-4a76-9be2-937a6f58cf9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9979308c-a9b1-4487-8f98-ea574a14df9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88019bca-96e7-4157-8604-0da2e5d4607e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7891d3ff-05f6-430e-adcd-018006a915af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf28c49-d38d-474f-9111-ecd3d07747f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b53af2a4-e6bb-4c27-9a4d-8a933bc9e7d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from torchvision import transforms\n",
    "import utils\n",
    "import torch\n",
    "from torch.utils import data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97621a0b-83c1-4ef3-8049-525876c8b74a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Args:\n",
    "    def __init__(self):\n",
    "        self.dataset = \"../../../datasets/weather_data/\" \n",
    "        self.crop_size = 224\n",
    "        self.interpolation = \"bilinear\"\n",
    "        self.aug_type = \"rand\"\n",
    "        self.val_resize = 256\n",
    "        self.gray = True\n",
    "        self.mag_bins = 31\n",
    "        self.hflip = 0.5\n",
    "        self.num_workers = 8\n",
    "        self.seed = 999777333\n",
    "        \n",
    "\n",
    "args = Args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2749511d-a2b8-44c9-8f96-c3adf09fd0fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_transforms = utils.get_data_augmentation(args)\n",
    "image_dataset = utils.load_image_dataset(args.dataset)\n",
    "\n",
    "\n",
    "# def resize(examples):\n",
    "#     examples[\"pixel_values\"] = [image.convert(\"RGB\").resize((300, 300)) for image in examples[\"image\"]]\n",
    "#     return examples\n",
    "\n",
    "def preprocess_train(example_batch):\n",
    "    example_batch[\"pixel_values\"] = [\n",
    "        data_transforms[\"train\"](image.convert(\"RGB\")) for image in example_batch[\"image\"]\n",
    "    ]\n",
    "    return example_batch\n",
    "\n",
    "def preprocess_val(example_batch):\n",
    "    example_batch[\"pixel_values\"] = [\n",
    "        data_transforms[\"val\"](image.convert(\"RGB\")) for image in example_batch[\"image\"]\n",
    "    ]\n",
    "    return example_batch\n",
    "\n",
    "# image_dataset = image_dataset.map(resize, remove_columns=[\"image\"], batched=True)\n",
    "\n",
    "train_dataset = image_dataset[\"train\"].with_transform(preprocess_train)\n",
    "val_dataset = image_dataset[\"validation\"].with_transform(preprocess_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4837a60f-7491-4f6e-be08-2beb1b7c7f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(examples):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for example in examples:\n",
    "        images.append((example[\"pixel_values\"]))\n",
    "        labels.append(example[\"labels\"])\n",
    "        \n",
    "    pixel_values = torch.stack(images)\n",
    "    labels = torch.tensor(labels)\n",
    "    return {\"pixel_values\": pixel_values, \"labels\": labels}\n",
    "\n",
    "dataloader = DataLoader(dataset, collate_fn=collate_fn, batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b6a71e-d375-41d8-99f2-4d068246b948",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "g = torch.Generator()\n",
    "g.manual_seed(args.seed)\n",
    "    \n",
    "image_datasets = {\n",
    "    \"train\": train_dataset,\n",
    "    \"val\": val_dataset\n",
    "}\n",
    "\n",
    "samplers = {\n",
    "    \"train\": data.RandomSampler(train_dataset),\n",
    "    \"val\": data.SequentialSampler(train_dataset),\n",
    "}\n",
    "dataloaders = {\n",
    "    x: data.DataLoader(\n",
    "        image_datasets[x],\n",
    "        collate_fn=collate_fn,\n",
    "        batch_size=batch_size,\n",
    "        sampler=samplers[x],\n",
    "        num_workers=args.num_workers,\n",
    "        worker_init_fn=utils.set_seed_for_worker,\n",
    "        generator=g,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "    for x in [\"train\", \"val\"]\n",
    "}\n",
    "\n",
    "train_loader, val_loader = dataloaders[\"train\"], dataloaders[\"val\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89cd2150-9f86-4bce-819e-2a3955d2734c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for batch in train_loader:\n",
    "    print(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9166e797-e960-475c-b90a-e6cdb27bbbf3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a1a553-7906-4886-8e10-2cb5b66c1cbb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef240f8c-3d4d-42ca-8b98-03e9416b08c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a9d557d-85ac-44a7-9c3b-f8b4eb816586",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d60dad-6afd-4564-9292-8714ef5d3727",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61778ce9-caba-4e51-b18d-f639490c5dfb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c9da66-32a2-4012-972a-7d493252fa3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b197c6-3c1a-451d-9e7c-0e8a47eef6c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aea1115-7ce0-4deb-b363-6a6c062d5ace",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a62632bd-e422-49d5-880d-1d9e1e89abde",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "360125d5-53ff-4954-9619-3836bbb87950",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "219e7afb-c74d-4500-89ed-93a2a88be010",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1633737e-758d-4d89-847c-aa2756b41ae3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "723510dd-8bdf-4b9d-9213-e25241c087c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c62651-15dd-43ee-abb5-44e0a4298749",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df4b0748-7970-4127-acb1-8fa9d7fe8aea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "311bf13c-167b-404b-9f08-50394d979387",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4acdc1f8-b9b1-4024-8008-d04dfcdcc8e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "169ecafe-7c49-4ece-9e1d-6043ccbb9305",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a831b48-9c68-4404-85b0-400ebac5293b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f6b200-2057-4a9c-9f23-55b2d91ec6b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c076fd97-e861-44d1-ad45-b8ca33d93f09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd40d47-5911-4b95-9162-3c0e238ffabd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141962fb-f818-476b-afff-c54ca04e6dcd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f932ca14-ff9c-409d-9014-0aa52ee9395d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc75bdc-da9f-48dd-8712-1ea89d54a48e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b7dfd1-b008-433a-acf3-61b9ab97d78b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a198eab2-e6d1-43d3-8179-0a4bc93ed84f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee6e335-2a09-4cf6-bf34-f7637a9ee540",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "img = ds[\"train\"][294][\"pixel_values\"]\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4192ed61-ba55-468b-9265-e8346f4bb011",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lowcode",
   "language": "python",
   "name": "lowcode"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
